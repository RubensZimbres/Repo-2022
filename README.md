# Repo-2022  
  
<b>Cellular Automaton</b>  
In this Python file, I add a cellular automaton to a PyTorch kernel, add a residual layer to achieve 99.29% accuracy on test set in MNIST, results better than Robust Training in High Dimensions via Block Coordinate Geometric Median Descent", by Google AI and Amazon Search (2021).
  
<b>TF-Keras</b>  
This folder has the code to customize ResNet Architecture via dictionary config, changing first two layers to receive multispectral images with 9 channels. Final layers are also added, for training and inference.  
  
<b>Santa Fe</b>  
This folder has the python code to create Agent-Based Models based in 2 and 5 state cellular automata.  

<img src=https://github.com/RubensZimbres/Repo-2022/blob/main/png/MBA_github_noise_movie.gif>

<img src=https://github.com/RubensZimbres/Repo-2022/blob/main/SantaFe/NetLogo/NETLOGO_28.png>

<b>Tensorflow Hub</b>  
This folder has the code to generate word embeddings using BERT multilingual model from Tensorflow Hub, in the shape (2,768).  
  
<b>Wav2Vec</b>  
Here you can find Python code to finetune Wav2Vec model (300 MB) of Speech Recognition on Common Voice dataset, as well as the code for evaluating the model. 
  
<b>Wav2Vec2-Large-xlsr</b>  
These files allow the training of Facebook's Wav2Vec2-Large-xlsr (model 1.5 GB) on Common Voice dataset on a RTX 2060. Some layers are frozen to allow fit in the GPU. Paper available at: <a href="url">https://arxiv.org/abs/2006.11477</a>. A pretrained version of the model is at my Hugging Face repository - Rubens Zimbres: 
<a href="url">https://huggingface.co/Rubens/Wav2Vec2-Large-XLSR-53-a-Portuguese</a>  
